{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/34478398/import-local-function-from-a-module-housed-in-another-directory-with-relative-im\n",
    "from os import chdir\n",
    "chdir('../')\n",
    "import lib.sklearn_preprocessing_lib as preprocessing\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text1 = \"Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.\"\n",
    "\n",
    "text2 = \"The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\"\n",
    "\n",
    "text3 = \"During the 1970s, many programmers began to write conceptual ontologies, which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 6), ('translation', 5), ('machine', 4), ('was', 3), ('in', 3), ('research', 2), ('that', 2), ('and', 1), ('slower', 1), ('be', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 去掉标点符号\n",
    "tokens = preprocessing.get_tokens(text2)\n",
    "count = Counter(tokens)\n",
    "print (count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('translation', 5), ('machine', 4), ('research', 2), ('slower', 1), ('tenyearlong', 1), ('developed', 1), ('within', 1), ('problem2', 1), ('years', 1), ('1980s', 1)]\n"
     ]
    }
   ],
   "source": [
    "#完成了去停用词\n",
    "tokens = preprocessing.get_tokens(text2)\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)\n",
    "print (count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({u'languag': 7, u'natur': 6, u'comput': 4, u'process': 3, u'concern': 2, u'frequent': 2, 'nlp': 1, u'challeng': 1, u'humancomput': 1, u'connect': 1, 'human': 1, u'artifici': 1, u'involv': 1, 'field': 1, u'interact': 1, u'system': 1, u'intellig': 1, u'percept': 1, u'program': 1, u'larg': 1, u'scienc': 1, u'machin': 1, u'form': 1, u'gener': 1, u'fruit': 1, u'understand': 1, 'thereof': 1, 'particular': 1, 'formal': 1, 'corpora': 1, u'machineread': 1, u'combin': 1, 'dialog': 1, u'logic': 1, u'linguist': 1, u'manag': 1})\n",
      "Top words in document 1\n",
      "\tWord: languag, TF-IDF: 0.14241\n",
      "\tWord: natur, TF-IDF: 0.12207\n",
      "\tWord: comput, TF-IDF: 0.08138\n",
      "\tWord: process, TF-IDF: 0.06103\n",
      "\tWord: concern, TF-IDF: 0.04069\n",
      "Counter({u'translat': 5, u'machin': 4, 'research': 2, u'fulfil': 1, u'claim': 1, 'slower': 1, 'tenyearlong': 1, 'within': 1, 'problem2': 1, u'automat': 1, u'system': 1, 'russian': 1, u'expect': 1, u'year': 1, u'fail': 1, 'alpac': 1, u'involv': 1, u'develop': 1, 'would': 1, u'author': 1, '1966': 1, 'three': 1, u'littl': 1, 'late': 1, 'report': 1, 'much': 1, u'conduct': 1, u'progress': 1, u'experi': 1, 'georgetown': 1, u'sixti': 1, u'sentenc': 1, '1954': 1, 'five': 1, 'found': 1, u'solv': 1, u'reduc': 1, u'1980': 1, u'fund': 1, u'howev': 1, u'dramat': 1, u'statist': 1, 'english': 1, 'real': 1, u'fulli': 1, 'first': 1})\n",
      "Top words in document 2\n",
      "\tWord: translat, TF-IDF: 0.10172\n",
      "\tWord: research, TF-IDF: 0.04069\n",
      "\tWord: machin, TF-IDF: 0.03003\n",
      "\tWord: fulfil, TF-IDF: 0.02034\n",
      "\tWord: claim, TF-IDF: 0.02034\n",
      "Counter({'lehnert': 2, u'mani': 2, '1978': 2, 'sam': 1, u'ontolog': 1, 'qualm': 1, 'meehan': 1, u'computerunderstand': 1, u'unit': 1, 'plot': 1, u'inform': 1, u'chatterbot': 1, 'began': 1, 'write': 1, 'racter': 1, 'written': 1, u'includ': 1, 'talespin': 1, 'pam': 1, u'polit': 1, 'schank': 1, u'carbonel': 1, 'cullingford': 1, 'realworld': 1, u'margi': 1, 'data': 1, u'parri': 1, '1977': 1, '1979': 1, u'wilenski': 1, '1976': 1, '1975': 1, '1981': 1, u'structur': 1, u'1970': 1, u'conceptu': 1, u'exampl': 1, u'jabberwacki': 1, 'time': 1, u'programm': 1})\n",
      "Top words in document 3\n",
      "\tWord: lehnert, TF-IDF: 0.0511\n",
      "\tWord: 1978, TF-IDF: 0.0511\n",
      "\tWord: mani, TF-IDF: 0.0511\n",
      "\tWord: sam, TF-IDF: 0.02555\n",
      "\tWord: ontolog, TF-IDF: 0.02555\n"
     ]
    }
   ],
   "source": [
    "# enumerate()是python的内置函数,enumerate在字典上是枚举、列举的意思,\n",
    "# 对于一个可迭代的（iterable）/可遍历的对象（如列表、字符串），enumerate将其组成一个索引序列，利用它可以同时获得索引和值\n",
    "# enumerate多用于在for循环中得到计数\n",
    "texts = [text1, text2, text3]\n",
    "\n",
    "countlist = []\n",
    "for text in texts:\n",
    "    countlist.append(preprocessing.count_term(text))\n",
    "\n",
    "for i, count in enumerate(countlist):\n",
    "    print count\n",
    "    print(\"Top words in document {}\".format(i + 1))\n",
    "    scores = {word: preprocessing.tfidf(word, count, countlist) for word in count}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:5]:\n",
    "        print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 语料\n",
    "corpus = [\n",
    "    \"Natural language processing (NLP) is a field of computer science, artificial intelligence and computational linguistics concerned with the interactions between computers and human (natural) languages, and, in particular, concerned with programming computers to fruitfully process large natural language corpora. Challenges in natural language processing frequently involve natural language understanding, natural language generation (frequently from formal, machine-readable logical forms), connecting language and machine perception, managing human-computer dialog systems, or some combination thereof.\",\n",
    "    \"The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem.[2] However, real progress was much slower, and after the ALPAC report in 1966, which found that ten-year-long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\",\n",
    "     \"During the 1970s, many programmers began to write conceptual ontologies, which structured real-world information into computer-understandable data. Examples are MARGIE (Schank, 1975), SAM (Cullingford, 1978), PAM (Wilensky, 1978), TaleSpin (Meehan, 1976), QUALM (Lehnert, 1977), Politics (Carbonell, 1979), and Plot Units (Lehnert 1981). During this time, many chatterbots were written including PARRY, Racter, and Jabberwacky\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.08271618,  0.        ,  0.        ,\n",
       "         0.08271618,  0.33086473,  0.        ,  0.        ,  0.16543237,\n",
       "         0.        ,  0.08271618,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.08271618,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.08271618,\n",
       "         0.08271618,  0.08271618,  0.16543237,  0.08271618,  0.        ,\n",
       "         0.        ,  0.        ,  0.08271618,  0.        ,  0.        ,\n",
       "         0.08271618,  0.08271618,  0.        ,  0.        ,  0.08271618,\n",
       "         0.08271618,  0.06290779,  0.        ,  0.57901329,  0.08271618,\n",
       "         0.        ,  0.        ,  0.08271618,  0.        ,  0.08271618,\n",
       "         0.06290779,  0.08271618,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.4962971 ,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.08271618,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.24814855,  0.08271618,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.08271618,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.08271618,\n",
       "         0.        ,  0.        ,  0.        ,  0.08271618,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.10987499,  0.10987499,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.10987499,  0.        ,\n",
       "         0.10987499,  0.10987499,  0.        ,  0.10987499,  0.10987499,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.10987499,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.10987499,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.10987499,  0.        ,  0.10987499,  0.        ,  0.10987499,\n",
       "         0.        ,  0.10987499,  0.10987499,  0.10987499,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.10987499,\n",
       "         0.10987499,  0.10987499,  0.        ,  0.10987499,  0.10987499,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.08356276,  0.        ,  0.        ,  0.        ,\n",
       "         0.10987499,  0.        ,  0.        ,  0.10987499,  0.        ,\n",
       "         0.33425105,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.10987499,  0.        ,  0.        ,  0.        ,  0.10987499,\n",
       "         0.        ,  0.        ,  0.10987499,  0.        ,  0.10987499,\n",
       "         0.10987499,  0.21974998,  0.10987499,  0.        ,  0.        ,\n",
       "         0.        ,  0.10987499,  0.10987499,  0.10987499,  0.10987499,\n",
       "         0.10987499,  0.        ,  0.        ,  0.10987499,  0.        ,\n",
       "         0.        ,  0.        ,  0.54937496,  0.        ,  0.        ,\n",
       "         0.32962497,  0.        ,  0.        ,  0.        ,  0.10987499],\n",
       "       [ 0.        ,  0.        ,  0.13608276,  0.13608276,  0.13608276,\n",
       "         0.13608276,  0.27216553,  0.13608276,  0.        ,  0.13608276,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.13608276,  0.13608276,  0.        ,  0.13608276,  0.        ,\n",
       "         0.        ,  0.        ,  0.13608276,  0.13608276,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.13608276,  0.13608276,\n",
       "         0.        ,  0.        ,  0.        ,  0.27216553,  0.        ,\n",
       "         0.13608276,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.13608276,  0.13608276,  0.        ,\n",
       "         0.        ,  0.        ,  0.13608276,  0.        ,  0.        ,\n",
       "         0.        ,  0.27216553,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.27216553,  0.13608276,\n",
       "         0.13608276,  0.        ,  0.        ,  0.13608276,  0.13608276,\n",
       "         0.13608276,  0.        ,  0.        ,  0.13608276,  0.13608276,\n",
       "         0.        ,  0.        ,  0.        ,  0.13608276,  0.        ,\n",
       "         0.13608276,  0.13608276,  0.        ,  0.13608276,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.13608276,  0.13608276,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.13608276,  0.13608276,  0.        ,  0.        ,\n",
       "         0.13608276,  0.13608276,  0.        ,  0.        ,  0.13608276,\n",
       "         0.        ,  0.13608276,  0.13608276,  0.13608276,  0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.tfidf_vectorizer(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这是一个标题\n",
    "## 子标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
